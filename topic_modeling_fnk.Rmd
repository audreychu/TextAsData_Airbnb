---
title: "Text as Data Project - Airbnb Topic Modeling"
author: "Audrey Chu ac8839, Faizan Kanji fnk9850"
date: "5/1/2022"
output:
  pdf_document: default
  html_document:
    df_print: paged
---


------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
```


```{r echo=TRUE, warning=FALSE}
# import libraries
libraries <- c("topicmodels", "dplyr", "stm", "quanteda")
lapply(libraries, require, character.only = T)

library(ggplot2)
library(stringi)
library(quanteda.corpora)
library(quanteda.textstats)
library(quanteda.textplots)
library(xgboost)
library(caret)
```

# Data Preparation
We use airbnb data scraped every June from 2018 to 2021 for our analysis

```{r echo=TRUE, warning=FALSE}

#Get and prepare data

setwd('/Users/faizankanji/NYU Classes/Spring 2022/Text as Data/Project/TextAsData_Airbnb')

# Read data for June of 2018-21
june_2018 = read.csv("Data/2018-06/listings.csv")
june_2019 = read.csv("Data/2019-06/listings.csv")
june_2020 = read.csv("Data/2020-06/listings.csv")
june_2021 = read.csv("Data/2021-06/listings.csv")

#2021 ratings changed to a 5 point scale from a 100 point scale. Convert back to 100 point scale
june_2021$review_scores_rating = (june_2021$review_scores_rating / 5) * 100


# Combine into one df
names_2018 = names(june_2018)
names_2019 = names(june_2019)
names_2020 = names(june_2020)
names_2021 = names(june_2021)

common_cols = Reduce(intersect, list(names_2018, names_2019, names_2020, names_2021))

data = rbind(june_2018[common_cols], june_2019[common_cols], june_2020[common_cols], june_2021[common_cols])

# Create Data Variable
data$date = as.Date(data$last_scraped)

# Remove entries with less than 5 reviews and where rating is null
data = data %>% filter (number_of_reviews >= 5)

data = data[!is.na(data$review_scores_rating),]

data$year = format(data$date, format="%Y")
data$price = as.numeric(gsub('[$,]', '', data$price))
data$text = data$description

```


```{r echo=TRUE, message=FALSE}
# only keep some relevant columns (for memory efficiency)
relevant_cols = c("text", "neighbourhood_group_cleansed", "property_type", "room_type", "accommodates", "bathrooms", "bedrooms", "beds", "price", "number_of_reviews", "review_scores_rating", "date", "year", "host_id")
data = data[relevant_cols]

```

# EDA and Data Cleanup

```{r echo=TRUE, message=FALSE}
# Basic EDA
# Most ratings are above 90
hist(data$review_scores_rating)

#Median rating is 96
summary(data$review_scores_rating)


```
Since the median rating is 96, and distribution of ratings is heavily skewed towards higher ratings, we create a High-Medium-Low rating scale with High being the top quartile, Low being the bottom quartile and Medium being the rest.

```{r echo=TRUE, message=FALSE}

data = data %>%
    mutate(final_rating = case_when(review_scores_rating >= 98 ~ 'High',
                                  review_scores_rating <= 92 ~ 'Low',
                                  TRUE ~ 'Medium'))

data$final_rating = as.factor(data$final_rating)
barplot(table(data$final_rating))

```
Next we remove solitary letters and html tags from our review text. We also convert all words to lowercase, remove stopwords and punctuations before converting our corpus of Airbnb descriptions to a dfm.

```{r echo=TRUE, message=FALSE}

# Remove non ASCII characters
data$text = stringi::stri_trans_general(data$text, "latin-ascii")

# Removes solitary letters
data$text = gsub(" [A-z] ", " ", data$text)
data$text = gsub("<.*?>", "", data$text)

stm_dfm <- dfm(corpus(data), remove_punct = TRUE, tolower = TRUE)
stm_dfm = dfm_remove(stm_dfm, c(stopwords("english"), "http","https","rt", "t.co"))

```


```{r echo=TRUE, message=FALSE}
# Look at most common words in word cloud
textplot_wordcloud(stm_dfm, min_size=1, max_size=4.5, max_words = 150)
```


# Run and Evaluate Topic Models

## Topic Model 1: Using 100 Topics

```{r echo=TRUE, message=FALSE}

# The full dataset is very large so take a sample to run stm on
set.seed(120)
sampled_data = sample_n(data, 30000)
sampled_stm_dfm <- dfm(corpus(sampled_data), remove_punct = TRUE, tolower = TRUE)
sampled_stm_dfm = dfm_remove(sampled_stm_dfm, c(stopwords("english"), "http","https","rt", "t.co"))

stm_dfm_trimmed = dfm_trim(sampled_stm_dfm, min_docfreq=50)

# Below code is the code used to run stm. Commented out for efficiency

#stm1 <- stm(stm_dfm_trimmed[rowSums(stm_dfm_trimmed)!=0,], K=100, seed=100, prevalence =~final_rating + as.numeric(year) + price, data=sampled_data[rowSums(stm_dfm_trimmed)!=0,], reportevery = 10, verbose=T)
```

```{r echo=TRUE, warning=FALSE}

#Loading the stm model for knitting

#saveRDS(stm1, "airbnb_topic_model_100_topics_sample_updated.rds")
stm1 <- readRDS("airbnb_topic_model_100_topics_sample_updated.rds")
```

```{r echo=TRUE, warning=FALSE}
print(paste0("the number of iterations to converge were: ", stm1$convergence$its))
```


```{r echo=TRUE, warning=FALSE}
plot(stm1, type = "summary", n= 3, text.cex=.4)
```

We will now focus on the top 10 and bottom 10 topics
```{r echo=TRUE, warning=FALSE}
#Top Topics:
# 58, 1, 80, 44, 39, 78, 99, 62, 63, 68
#Bottom Topics:
# 8, 85, 2, 42, 20, 96, 5, 84, 87, 28

#Plotting top
plot(stm1, type = "label",  text.cex=.6, topics=c(58, 1, 80, 44, 39), main = "Top 10 Topics: 1-5")
plot(stm1, type = "label",  text.cex=.6, topics=c(78, 99, 62, 63, 68), main = "Top 10 Topics: 6-10")

#Plotting Bottom
plot(stm1, type = "label",  text.cex=.6, topics=c(8, 85, 2, 42, 20), main = "Bottom 10 Topics: 10-6")
plot(stm1, type = "label",  text.cex=.6, topics=c(96, 5, 84, 87, 28), main = "Bottom 10 Topics: 5-1")

```
The top 10 topics found by the model can be named as follows:
1) Topic 58: Room Types
2) Topic 1: Room Features
3) Topic 80: Bedding Availability
4) Topic 44: Host Welcoming Guests
5) Topic 39: Small Apartments in Walk-up Buildings
6) Topic 78: Apartments Near Subway
7) Topic 99: Nearby transportation
8) Topic 62: Light, Restaurants and Bars nearby
9) Topic 63: Stay Instructions
10) Topic 68: Relaxing Day in NYC

Let's look at some examples from the top two topics:
```{r echo=TRUE, warning=FALSE}
thoughts58 <- findThoughts(stm1, texts = sampled_data[rowSums(stm_dfm_trimmed)!=0,]$text, n = 2, topics = 58)$docs[[1]]
thoughts1 <- findThoughts(stm1, texts = sampled_data[rowSums(stm_dfm_trimmed)!=0,]$text, n = 2, topics = 1)$docs[[1]]

thoughts58
thoughts1

```



We will now analyze topic prevalance with various covariates such as year, rating and price.

```{r echo=TRUE, warning=FALSE, fig.height = 4}
#Top Topics:
# 58, 1, 80, 44, 39, 78, 99, 62, 63, 68
#Bottom Topics:
# 8, 85, 2, 42, 20, 96, 5, 84, 87, 28

top_topics = c(58, 1, 80, 44, 39, 78, 99, 62, 63, 68)
top_topic_names = c("Room Types", "Room Features", "Bedding Availability", "Host Welcoming Guests", 
                    "Small Apartments in Walk-up Buildings", "Apartments Near Subway", "Nearby transportation",
                    "Light, Restaurants and Bars nearby", "Stay Instructions", "Relaxing Day in NYC")

sampled_data$year_factor = as.factor(sampled_data$year)

prep = estimateEffect(top_topics ~ final_rating + year_factor + s(price), stm1, 
                      metadata = sampled_data[rowSums(stm_dfm_trimmed)!=0,], uncertainty = "Global")

#sampled_data$numeric_date = as.numeric(sampled_data$date)
#year_effect<- estimateEffect(c(4, 7) ~ year_n, stm1, meta=sampled_data[rowSums(stm_dfm_trimmed)!=0,])

plot(prep, "final_rating", method = "difference", cov.value1 = "High", cov.value2 = "Low", model=stm1, xlab="prevalence", xlim=c(-.015, .015), labeltype = "custom", custom.labels=top_topic_names)

```


```{r echo=TRUE, warning=FALSE, fig.height = 3.5}
sampled_data$numeric_year = as.numeric(sampled_data$year)
  
prep_2 = estimateEffect(top_topics ~ s(numeric_year), stm1, 
                      metadata = sampled_data[rowSums(stm_dfm_trimmed)!=0,], uncertainty = "Global")

plot(prep_2, "numeric_year", method = "continuous", model=stm1, xlab="year", topics=c(58, 1, 80, 44, 39), labeltype = "custom", custom.labels=top_topic_names[1:5])

```



```{r echo=TRUE, warning=FALSE, fig.height = 4}
plot(prep, "year_factor", method = "difference", cov.value1 = 2021, cov.value2 = 2018, model=stm1, xlab="prevalence", xlim=c(-.015, .015), labeltype = "custom", custom.labels=top_topic_names)

```

```{r echo=TRUE, warning=FALSE, fig.height = 3.5}
prep_3 = estimateEffect(top_topics ~ s(review_scores_rating), stm1, 
                      metadata = sampled_data[rowSums(stm_dfm_trimmed)!=0,], uncertainty = "Global")

plot(prep_3, "review_scores_rating", method = "continuous", model=stm1, xlab="rating", topics=c(58, 1, 80, 44, 39), xlim=c(85, 100), ylim=c(0.01, 0.04), labeltype = "custom", custom.labels=top_topic_names[1:5])

```


## Topic Model 2: Using 20 Topics

```{r echo=TRUE, message=FALSE}
# Try with fewer topics

#stm2 <- stm(stm_dfm_trimmed[rowSums(stm_dfm_trimmed)!=0,], K=20, seed=200, prevalence =~final_rating + s(as.numeric(year)) + price, data=sampled_data[rowSums(stm_dfm_trimmed)!=0,], reportevery = 10, verbose=T)
```


```{r echo=TRUE, warning=FALSE}

#Loading the stm model for knitting

#saveRDS(stm2, "airbnb_topic_model_20_topics_sample_updated.rds")
stm2 <- readRDS("airbnb_topic_model_20_topics_sample_updated.rds")
```

```{r echo=TRUE, warning=FALSE}
print(paste0("the number of iterations to converge were: ", stm2$convergence$its))
```


```{r echo=TRUE, warning=FALSE}
plot(stm2, type = "summary", n= 5, text.cex=.6)
```

```{r echo=TRUE, warning=FALSE}
#Top Topics:
# 1, 3, 12, 19, 9, 7, 8, 11, 10, 14

#Plotting top
plot(stm2, type = "label",  text.cex=.6, topics=c(1, 3, 12, 19, 9), main = "Top 10 Topics: 1-5")
plot(stm2, type = "label",  text.cex=.6, topics=c(7, 8, 11, 10, 14), main = "Top 10 Topics: 6-10")

```
The top 10 topics found by the model can be named as follows:
1) Topic 1: Room Types
2) Topic 3: Welcoming to Host's Home
3) Topic 12: Near Train in Manhattan
4) Topic 19: Apartment amenities
5) Topic 9: Large and Modern Apartments
6) Topic 7: Luxury Homes
7) Topic 8: Stay Instructions
8) Topic 11: Brooklyn Apartments
9) Topic 10: Tourist Locations
10) Topic 14: Bedding Availability

Let's look at some examples from the top two topics:

```{r echo=TRUE, warning=FALSE}
thoughts1 <- findThoughts(stm2, texts = sampled_data[rowSums(stm_dfm_trimmed)!=0,]$text, n = 2, topics = 1)$docs[[1]]
thoughts3 <- findThoughts(stm2, texts = sampled_data[rowSums(stm_dfm_trimmed)!=0,]$text, n = 2, topics = 3)$docs[[1]]

thoughts1
thoughts3

```





```{r echo=TRUE, warning=FALSE, fig.height=4}
#Top Topics:
# 1, 3, 12, 19, 9, 7, 8, 11, 10, 14

top_topics = c(1, 3, 12, 19, 9, 7, 8, 11, 10, 14)
top_topic_names = c("Room Types", "Welcoming to Host's Home", "Near Train in Manhattan", 
                    "Apartment amenities", "Large and Modern Apartments", "Luxury Homes", "Stay Instructions",
                    "Brooklyn Apartments", "Tourist Locations", "Bedding Availability")


sampled_data$year_factor = as.factor(sampled_data$year)

prep = estimateEffect(top_topics ~ final_rating + year_factor + s(price), stm2, 
                      metadata = sampled_data[rowSums(stm_dfm_trimmed)!=0,], uncertainty = "Global")

plot(prep, "final_rating", method = "difference", cov.value1 = "High", cov.value2 = "Low", model=stm2, xlab="prevalence", xlim=c(-.03, .03), labeltype = "custom", custom.labels=top_topic_names)

```


```{r echo=TRUE, warning=FALSE, fig.height=4.5}
sampled_data$numeric_year = as.numeric(sampled_data$year)
  
prep_2 = estimateEffect(top_topics ~ s(numeric_year), stm2, 
                      metadata = sampled_data[rowSums(stm_dfm_trimmed)!=0,], uncertainty = "Global")

plot(prep_2, "numeric_year", method = "continuous", model=stm2, xlab="year", topics=c(1, 3, 12, 19, 9), labeltype = "custom", custom.labels=top_topic_names[1:5])

plot(prep_2, "numeric_year", method = "continuous", model=stm2, xlab="year", topics=c(7, 8, 11, 10, 14), labeltype = "custom", custom.labels=top_topic_names[6:10])

```



```{r echo=TRUE, warning=FALSE, fig.height=4}
plot(prep, "year_factor", method = "difference", cov.value1 = 2021, cov.value2 = 2018, model=stm2, xlab="prevalence", xlim=c(-.03, .03), labeltype = "custom", custom.labels=top_topic_names)

```

```{r echo=TRUE, warning=FALSE, fig.height=4.5}
prep_3 = estimateEffect(top_topics ~ s(review_scores_rating), stm2, 
                      metadata = sampled_data[rowSums(stm_dfm_trimmed)!=0,], uncertainty = "Global")

plot(prep_3, "review_scores_rating", method = "continuous", model=stm2, xlab="year", topics=c(1, 3, 12, 19, 9), labeltype = "custom", xlim=c(85, 100), ylim=c(0.03, 0.1), custom.labels=top_topic_names[1:5])

plot(prep_3, "review_scores_rating", method = "continuous", model=stm2, xlab="year", topics=c(7, 8, 11, 10, 14), labeltype = "custom", xlim=c(85, 100), ylim=c(0.03, 0.1), custom.labels=top_topic_names[6:10])

```


```{r echo=TRUE, warning=FALSE}
stm::cloud(stm2, topic = 1, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 3, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 12, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 19, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 9, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 7, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 8, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 11, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 10, min_size=1, max_size=4.5,scale=c(3.5,0.25))
stm::cloud(stm2, topic = 14, min_size=1, max_size=4.5,scale=c(3.5,0.25))
```





# Scratch: Trying Modeling




```{r echo=TRUE, warning=FALSE}
sampled_data_for_model = sampled_data[rowSums(stm_dfm_trimmed)!=0,]
sampled_data_for_model = cbind(sampled_data_for_model, stm1$theta)

sampled_data_for_model = sampled_data_for_model %>% filter(final_rating == "High" | final_rating=="Low")
sampled_data_for_model$binary_rating = as.numeric(sampled_data_for_model$final_rating) - 1

set.seed(1984L)
prop_train <- 0.8 #we will use 80% of the data as our training set
# Save the indexes

hosts = unique(sampled_data_for_model$host_id)

ids <- 1:length(hosts)

ids_train <- sample(ids, ceiling(prop_train*length(ids)), replace = FALSE)
ids_test <- ids[-ids_train]
hosts_train = hosts[ids_train]
hosts_test = hosts[ids_test]

prop_cols = as.character(seq(1, 100))

train_prop <- (sampled_data_for_model %>% filter(host_id %in% hosts_train))[prop_cols]
train_label <- (sampled_data_for_model %>% filter(host_id %in% hosts_train))["binary_rating"]
test_prop <- (sampled_data_for_model %>% filter(host_id %in% hosts_test))[prop_cols]
test_label <- (sampled_data_for_model %>% filter(host_id %in% hosts_test))["binary_rating"]

```






```{r echo=TRUE, warning=FALSE}
# sampled_data_for_model = sampled_data[rowSums(stm_dfm_trimmed)!=0,]
# sampled_data_for_model = cbind(sampled_data_for_model, stm1$theta)
# 
# sampled_data_for_model = sampled_data_for_model %>% filter(final_rating == "High" | final_rating=="Low")
# sampled_data_for_model$binary_rating = as.numeric(sampled_data_for_model$final_rating) - 1
# 
# set.seed(1984L)
# prop_train <- 0.8 #we will use 80% of the data as our training set
# # Save the indexes
# ids <- 1:nrow(sampled_data_for_model)
# 
# ids_train <- sample(ids, ceiling(prop_train*length(ids)), replace = FALSE)
# ids_test <- ids[-ids_train]
# prop_cols = as.character(seq(1, 100))
# train_prop <- sampled_data_for_model[ids_train,][prop_cols]
# train_label <- sampled_data_for_model[ids_train,]["binary_rating"]
# test_prop <- sampled_data_for_model[ids_test,][prop_cols]
# test_label <- sampled_data_for_model[ids_test,]["binary_rating"]

```


```{r echo=TRUE, warning=FALSE}

xgb <- xgboost(data = as.matrix(train_prop), label = as.matrix(train_label), nrounds= 100, objective = "binary:logistic")

```


```{r echo=TRUE, warning=FALSE}

pred = predict(xgb, as.matrix(test_prop))
prediction <- as.numeric(pred > 0.5)

# get confusion matrix (see slide 35 from class)
cmat <- table(as.matrix(test_label), prediction)
cmat
nb_acc <- sum(diag(cmat))/sum(cmat) # accuracy = (TP + TN) / (TP + FP + TN + FN)
nb_recall <- cmat[2,2]/sum(cmat[2,]) # recall = TP / (TP + FN)
nb_precision <- cmat[2,2]/sum(cmat[,2]) # precision = TP / (TP + FP)
nb_f1 <- 2*(nb_recall*nb_precision)/(nb_recall + nb_precision)

baseline_acc <- max(prop.table(table(as.matrix(test_label))))

# print
cat(
  "Baseline Accuracy: ", baseline_acc, "\n",
  "Accuracy:",  nb_acc, "\n",
  "Recall:",  nb_recall, "\n",
  "Precision:",  nb_precision, "\n",
  "F1-score:", nb_f1
)

```

```{r echo=TRUE, warning=FALSE}
# Compute feature importance matrix
importance_matrix <- xgb.importance(prop_cols, model = xgb)
# Nice graph
xgb.plot.importance(importance_matrix[1:10,])

```


```{r echo=TRUE, warning=FALSE}
important_topics = as.numeric(importance_matrix[1:10,]$Feature)
plot(stm1, type = "label",  text.cex=.6, topics=important_topics[1:5])

prep = estimateEffect(important_topics ~ final_rating, stm1, 
                      metadata = sampled_data[rowSums(stm_dfm_trimmed)!=0,])

#sampled_data$numeric_date = as.numeric(sampled_data$date)
#year_effect<- estimateEffect(c(4, 7) ~ year_n, stm1, meta=sampled_data[rowSums(stm_dfm_trimmed)!=0,])

plot(prep, "final_rating", method = "difference", cov.value1 = "High", cov.value2 = "Low", model=stm1, xlab="prevalence", xlim=c(-.015, .015), labeltype = "custom", custom.labels=important_topics)


cloud()

```







```{r echo=TRUE, warning=FALSE}

#Get and prepare data

# Read data for June of 2018-21
dec_2021 = read.csv("Data/2021-12/listings.csv")

#2021 ratings changed to a 5 point scale from a 100 point scale. Convert back to 100 point scale
dec_2021$review_scores_rating = (dec_2021$review_scores_rating / 5) * 100

# Create Data Variable
dec_2021$date = as.Date(dec_2021$last_scraped)

# Remove entries with less than 5 reviews and where rating is null
dec_2021 = dec_2021 %>% filter (number_of_reviews >= 5)

dec_2021 = dec_2021[!is.na(dec_2021$review_scores_rating),]

dec_2021$year = format(dec_2021$date, format="%Y")
dec_2021$price = as.numeric(gsub('[$,]', '', dec_2021$price))
dec_2021$text = dec_2021$description

```

```{r echo=TRUE, message=FALSE}
# only keep some relevant columns (for memory efficiency)
relevant_cols = c("text", "neighbourhood_group_cleansed", "property_type", "room_type", "accommodates", "bathrooms", "bedrooms", "beds", "price", "number_of_reviews", "review_scores_rating", "date", "year", "host_id")
dec_2021 = dec_2021[relevant_cols]

```

```{r echo=TRUE, message=FALSE}
# Basic EDA
# Most ratings are above 90
hist(dec_2021$review_scores_rating)

#Median rating is 96
summary(dec_2021$review_scores_rating)


```


```{r echo=TRUE, message=FALSE}

dec_2021 = dec_2021 %>%
    mutate(final_rating = case_when(review_scores_rating >= 98 ~ 'High',
                                  review_scores_rating <= 92 ~ 'Low',
                                  TRUE ~ 'Medium'))

dec_2021$final_rating = as.factor(dec_2021$final_rating)
barplot(table(dec_2021$final_rating))

```


```{r echo=TRUE, message=FALSE}

# Remove non ASCII characters
dec_2021$text = stringi::stri_trans_general(dec_2021$text, "latin-ascii")

# Removes solitary letters
dec_2021$text = gsub(" [A-z] ", " ", dec_2021$text)
dec_2021$text = gsub("<.*?>", "", dec_2021$text)

dec_2021 = dec_2021 %>% filter(final_rating == "High" | final_rating=="Low")
dec_2021$binary_rating = as.numeric(dec_2021$final_rating) - 1

dec_dfm <- dfm(corpus(dec_2021), remove_punct = TRUE, tolower = TRUE)
dec_dfm = dfm_remove(dec_dfm, c(stopwords("english"), "http","https","rt", "t.co"))

dec_2021 = dec_2021[rowSums(dec_dfm)!=0,]
dec_2021 = dec_2021[-8424, ]

dec_dfm <- dfm(corpus(dec_2021), remove_punct = TRUE, tolower = TRUE)
dec_dfm = dfm_remove(dec_dfm, c(stopwords("english"), "http","https","rt", "t.co"))

dec_dfm_stm = convert(dec_dfm, "stm")

old_dfm_stm = convert(stm_dfm_trimmed, "stm")

aligned = alignCorpus(dec_dfm_stm, old_dfm_stm$vocab)

new_stm = fitNewDocuments(stm1, aligned$documents)

```


```{r echo=TRUE, warning=FALSE}
#dec_for_model = dec_2021[rowSums(dec_dfm)!=0,]
#dec_for_model = dec_for_model[-8424, ]
dec_for_model = cbind(dec_2021, new_stm$theta)

dec_prop <- (dec_for_model %>% filter(!(host_id %in% hosts_train)))[prop_cols]
dec_label <- (dec_for_model %>% filter(!(host_id %in% hosts_train)))["binary_rating"]

```


```{r echo=TRUE, warning=FALSE}

pred = predict(xgb, as.matrix(dec_prop))
prediction <- as.numeric(pred > 0.5)

# get confusion matrix (see slide 35 from class)
cmat <- table(as.matrix(dec_label), prediction)
cmat
nb_acc <- sum(diag(cmat))/sum(cmat) # accuracy = (TP + TN) / (TP + FP + TN + FN)
nb_recall <- cmat[2,2]/sum(cmat[2,]) # recall = TP / (TP + FN)
nb_precision <- cmat[2,2]/sum(cmat[,2]) # precision = TP / (TP + FP)
nb_f1 <- 2*(nb_recall*nb_precision)/(nb_recall + nb_precision)

baseline_acc <- max(prop.table(table(as.matrix(dec_label))))

# print
cat(
  "Baseline Accuracy: ", baseline_acc, "\n",
  "Accuracy:",  nb_acc, "\n",
  "Recall:",  nb_recall, "\n",
  "Precision:",  nb_precision, "\n",
  "F1-score:", nb_f1
)

```